{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVB38cKkdwOz"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Carolina N√∫√±ez\n",
        "- Nombre de alumno 2: Alonso Uribe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_v30228dwOz"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorioüíª](https://github.com/carinunez/Labs_MDS/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset\n",
        "\n",
        "data_sets = create_data(n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3PQnEn7pjuHz"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "def plot_scatter(dataset):#x, y, color):\n",
        "    models = [KMeans, GaussianMixture, AgglomerativeClustering, DBSCAN]\n",
        "    # AgglometariveClustering tiene como par√°metro linkage=ward por defecto.\n",
        "    fig = make_subplots(3,4, column_titles=[model.__name__ for model in models], subplot_titles=list(range(1,13)))\n",
        "    fig.update_layout(dict(height=800, width=1000))\n",
        "    for annotation in fig['layout']['annotations'][-4:]:\n",
        "        annotation[\"y\"] = 1.02 # Lo mas cacho que he hecho en mi vida\n",
        "    for i, (name, ds) in enumerate(data_sets.items()):\n",
        "        for j, model in enumerate(models):\n",
        "            params = {}\n",
        "            if model.__name__!=\"DBSCAN\":\n",
        "                params = {\"n_clusters\" if model.__name__ in (\"KMeans\",\"AgglomerativeClustering\") else \"n_components\":ds[\"n_cluster\"]}\n",
        "            else:\n",
        "                params = {\"eps\":0.2}\n",
        "            ti = time.time()\n",
        "            new_classes = model(**params).fit_predict(ds[\"x\"])\n",
        "            tf = round((time.time() - ti)/1000, 5)\n",
        "            _x, _y = ds[\"x\"][:,0], ds[\"x\"][:,1]\n",
        "            silh = round(silhouette_score(ds[\"x\"], new_classes),3)\n",
        "            fig.add_trace(go.Scatter(x=_x, y=_y, mode=\"markers\", marker=dict(size=5, color=new_classes), showlegend=False), row=i+1, col=j+1)\n",
        "            subtitle = f\"{tf} [s]; S: {silh}\"\n",
        "            fig.layout.annotations[i*4+j].update(text=subtitle, font=dict(size=10))\n",
        "\n",
        "    fig.update_layout(title=\"Comparaci√≥n tiempo de ejecuci√≥n por t√©cnica\")\n",
        "    fig.show()\n",
        "\n",
        "samples = [1000,5000,10000]\n",
        "for sample in samples:\n",
        "    data_sets = create_data(sample)\n",
        "    plot_scatter(dataset=data_sets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfIbRmPbjp38"
      },
      "source": [
        "A medida que aumentan los puntos, tdos los modelos se ven afectados, m√°s notoriamente DBSCAN, apesar de que este mejora considerablemente la m√©trica, lo que hace sentido al haber mayor densidad de puntos producido por las distribuciones. Los dem√°s se mantienen constante en m√©trica salvo ciertas variaciones posiblemente azarosas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "# Carga de datos\n",
        "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "df.drop('id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XajtsMojdwO5"
      },
      "outputs": [],
      "source": [
        "# variables numericas\n",
        "numerical = df.select_dtypes('number').columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJnaSjOKBdmJ"
      },
      "source": [
        "2. Dado que los m√©todos no supervisados establecen relaciones entre variables, al usar variables categ√≥ricas no se puede calcular distancias o agrupaciones pues no tiene sentido calcular la distancia entre 2 categor√≠as, lo que podr√≠a comprometer el rendimiento del algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "l0P_rPR2BdmJ",
        "outputId": "5b9325fc-bdd6-491a-c7a7-41c361341d78"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(rows=3, cols=6, subplot_titles=numerical)\n",
        "\n",
        "for i, col in enumerate(numerical):\n",
        "    fig.add_trace(go.Histogram(x=df[col], name=col),\n",
        "                    row= 1 if i//6 == 0 else i//6 +1,\n",
        "                    col=i%6 +1)\n",
        "\n",
        "fig.update_layout(title_text='Distribuci√≥n de variables',\n",
        "                  height=800, width=1500)\n",
        "fig.update_yaxes(type='log', row=3, col=5)\n",
        "fig.update_yaxes(type='log', row=3, col=6)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw14445RBdmK"
      },
      "source": [
        "3. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "    - **Age:** presenta una distribuci√≥n similar a una gaussiana.\n",
        "    - **Flight Distance, Departure Delay in Minutes, Arrival Delay in Minutes:** tienen distribuciones decrecientes, similar a una exponencial decreciente.\n",
        "\n",
        "    En cuanto a las variables que dan cuenta de los niveles de satisfacci√≥n respecto a distintos aspectos del vuelo, se tiene:\n",
        "   - **'Inflight wifi service', 'Ease of Online booking':** estos datsets parecen tener un comportamiento similar a una gaussiana.\n",
        "   - **'Online boarding','Seat comfort','Inflight entertainment','On-board service','Leg room service','Baggage handling','Checkin service', 'Inflight service','Cleanliness'** estas variables tienen un comportamiento similar a una Beta.\n",
        "   - **'Departure/Arrival time convenient','Food and drink'** parecen tener un comportamiento uniforme, pues no see observan grandes preferencias.\n",
        "\n",
        "4. Dado que los datos tienen distinto rango de valores, ser√≠a buena idea escalarlos para mejorar el rendimiento del algoritmo. Adem√°s escalar variables como 'Departure Delay in Minutes' o 'Arribal Delay in Minutes' ayudar el trabajo con ellas debido a presencia de outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PZF7ia9SBdmK",
        "outputId": "852dd8fd-6527-4e94-8d4a-4f948760671a"
      },
      "outputs": [],
      "source": [
        "df_c = df[numerical].corr()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Heatmap(\n",
        "        x = df_c.columns,\n",
        "        y = df_c.index,\n",
        "        z = np.array(df_c),\n",
        "        text=df_c.values,\n",
        "        texttemplate='%{text:.2f}'\n",
        "    )\n",
        ")\n",
        "fig.update_layout(title_text='Correlaci√≥n entre las variables num√©ricas')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "LgFC-Of_BdmL",
        "outputId": "4fb35420-2e60-45f1-ba77-04a97677c618"
      },
      "outputs": [],
      "source": [
        "# Ordenamos las correlaciones usando su valor abs\n",
        "corr_sorted = np.abs(df_c.unstack()).sort_values()\n",
        "corr_sorted.head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFrdiglSBdmL"
      },
      "source": [
        "Teniendo en cuenta, que 2 variables con alta correlaci√≥n (en magnitud) dan cuenta de que estar√≠an entregando informaci√≥n similar, nos quedaremos con aquellas que presenten los menores valores de correlaci√≥n y con ello, que nos entregan la mayor cantidad de informaci√≥n posible.\n",
        "\n",
        "Entonces, al revisar los valores absolutos de las correlaciones, nos quedamos con las variables:\n",
        "- Departure/Arrival time convenient\n",
        "- Gate location\n",
        "- Online boarding\n",
        "- Arribal Delay in Minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4pHFNXPnBdmM"
      },
      "outputs": [],
      "source": [
        "# Dataset reducido\n",
        "keep_cols = ['Departure/Arrival time convenient', 'Online boarding',\n",
        "             'Arrival Delay in Minutes', 'Gate location']\n",
        "df_new = df[keep_cols].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-",
        "outputId": "0035a797-9b98-40ac-f193-dcb3db53a6dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Seleccionamos las columnas numericas\n",
        "num_cols_pipe = ColumnTransformer([\n",
        "                    (\"mantener\", \"passthrough\", numerical)],\n",
        "                     remainder=\"drop\", verbose_feature_names_out=False)\n",
        "\n",
        "# Seleccionamos las columnas a mantener\n",
        "keep_cols_pipe = ColumnTransformer([\n",
        "                    (\"mantener\", \"passthrough\", keep_cols)],\n",
        "                     remainder=\"drop\", verbose_feature_names_out=False)\n",
        "\n",
        "pca_pipeline = Pipeline([\n",
        "                        ('Numerical data', num_cols_pipe),\n",
        "                        ('S_scaler', StandardScaler()),\n",
        "                        ('keep cols', keep_cols_pipe),\n",
        "                        ('pca', PCA(n_components=2)) ])\n",
        "\n",
        "pca_pipeline.set_output(transform='pandas')\n",
        "\n",
        "df_pca = pca_pipeline.fit_transform(df)\n",
        "\n",
        "px.scatter(df_pca, x='pca0', y='pca1', title='Datos con PCA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "AFsv7hlABdmQ",
        "outputId": "7fea6636-68a9-4695-e8e5-d096645894b7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# IsolationForest -> 1% de outliers\n",
        "\n",
        "class IsolationForest2(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, contamination) -> None:\n",
        "        super().__init__()\n",
        "        self.contamination = contamination\n",
        "    def fit(self, X):\n",
        "        self.mask = IsolationForest(random_state=29, contamination=self.contamination).fit_predict(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.to_numpy() if isinstance(X, (pd.DataFrame, pd.Series)) else np.array(X)\n",
        "        self.inliers = []\n",
        "        self.outliers = []\n",
        "        for instance, inlier in zip(X, self.mask):\n",
        "            if inlier==1:\n",
        "                self.inliers.append(instance)\n",
        "            else:\n",
        "                self.outliers.append(instance)\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X).transform(X)\n",
        "        return np.array(self.inliers)#, np.array(self.outliers)\n",
        "\n",
        "    def set_output(self, transform='default'):\n",
        "        return self\n",
        "\n",
        "def identify_outliers(dataframe, n_contamination=0.01):\n",
        "    iso_f = IsolationForest(random_state=29, contamination=n_contamination)\n",
        "    iso_f.fit(dataframe)\n",
        "    dataframe['outliers'] = iso_f.predict(dataframe)\n",
        "    return dataframe\n",
        "\n",
        "outliers_pca_pipeline = Pipeline([\n",
        "                        ('Numerical data', num_cols_pipe),\n",
        "                        ('S_scaler', StandardScaler()),\n",
        "                        ('keep cols', keep_cols_pipe),\n",
        "                        ('find_outliers', FunctionTransformer(identify_outliers)),\n",
        "                        ('pca', ColumnTransformer([\n",
        "                                  # aplico PCA a las variables definidas previamente,\n",
        "                                  # manteniendo la etiqueta para saber si son outliers\n",
        "                                  ('pca_keep_outliers', PCA(n_components=2), keep_cols),\n",
        "                                  ('outliers', 'passthrough', ['outliers'])],\n",
        "                                   verbose_feature_names_out=False))\n",
        "                         ])\n",
        "\n",
        "outliers_pca_pipeline.set_output(transform='pandas')\n",
        "\n",
        "df_out_pca = outliers_pca_pipeline.fit_transform(df)\n",
        "\n",
        "px.scatter(df_out_pca, x='pca0', y='pca1', color='outliers',\n",
        "           title='Datos con IsolationForest y PCA')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24xP7KdvO2iK"
      },
      "source": [
        "_Importante:_ En caso de querer eliminar los outliers, debo cambiar ```FunctionTransformer(identify_outliers)``` por IsolationForest2 que retorna el dataframe sin outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFKcd1pPdqY"
      },
      "source": [
        "Dada la distribuci√≥n que tienen los datos en estas dimensiones, resulta dif√≠cil afirmar con certeza sobre qu√© puntos ser√≠an outliers. Sin embargo, es claro que los puntos que tienen 'pca1' mayor a 5 ser√≠an outliers (puntos azules) pues, los datos parecen agruparse en mayores menores a ese. Por otra parte, los datos no an√≥malos parecen seguir una distribuci√≥n gaussiana o semicircular, que se repite en cada agrupaci√≥n en diagonal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<!-- <img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Funci√≥n que contiene Gaussian Mixture y ser√° entregada a FunctionTransformer\n",
        "# para poder aplicar GMM dentro de otra pipeline\n",
        "def gaussian_m(dataframe, n_clusters):\n",
        "    gmm = GaussianMixture(random_state=29, n_components=n_clusters)\n",
        "    gmm.fit(dataframe)\n",
        "    df = dataframe.copy()\n",
        "    df['cluster'] = gmm.predict(dataframe)\n",
        "    df['aic'] = gmm.aic(dataframe)\n",
        "    df['bic'] = gmm.bic(dataframe)\n",
        "    return df\n",
        "\n",
        "outliers_pca_gmm_pipe = Pipeline([\n",
        "                        ('Numerical data', num_cols_pipe),\n",
        "                        ('S_scaler', StandardScaler()),\n",
        "                        ('keep cols', keep_cols_pipe),\n",
        "                        ('drop_outliers', IsolationForest2(contamination=0.01)),\n",
        "                        ('gaussian_mix', FunctionTransformer(gaussian_m)),\n",
        "                        ('pca', PCA(n_components=2)),\n",
        "                        ])\n",
        "\n",
        "outliers_pca_gmm_pipe.set_output(transform='pandas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rcNKOC5Bdmi",
        "outputId": "03a8a575-3092-4b58-ae9b-685fb31afbd5"
      },
      "outputs": [],
      "source": [
        "# Revisamos los par√°metros que recibe la Pipeline creada\n",
        "outliers_pca_gmm_pipe.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSkWgaT7Bdmj"
      },
      "outputs": [],
      "source": [
        "# Probamos con distintos n√∫meros de clusters\n",
        "clusters = pd.DataFrame()\n",
        "\n",
        "for n_cluster in range(3, 9):\n",
        "    outliers_pca_gmm_pipe.set_params(gaussian_mix__kw_args={'n_clusters': n_cluster})\n",
        "    df_out_gm = outliers_pca_gmm_pipe.fit_transform(df)\n",
        "    df_out_gm.rename(columns={'cluster': f'cluster_{n_cluster}',\n",
        "                              'aic': f'aic_{n_cluster}',\n",
        "                              'bic': f'bic_{n_cluster}'}, inplace=True)\n",
        "\n",
        "    clusters = pd.concat([clusters, df_out_gm], axis=1) # guardo los resultados gmm\n",
        "    clusters = clusters.loc[:,~clusters.columns.duplicated()] # elimino las cols duplicadas (pca0 y pca1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtQg49oKBdmk"
      },
      "outputs": [],
      "source": [
        "fig1 = px.scatter(clusters, x='pca0',y='pca1',color='cluster_3')\n",
        "fig1.update_layout(title_text='Clusters Gaussian Mixture 3 clusters', height=400, width=800)\n",
        "fig1.show()\n",
        "fig2 = px.scatter(clusters, x='pca0',y='pca1',color='cluster_5')\n",
        "fig2.update_layout(title_text='Clusters Gaussian Mixture 5 clusters', height=400, width=800)\n",
        "fig2.show()\n",
        "fig3 = px.scatter(clusters, x='pca0',y='pca1',color='cluster_8')\n",
        "fig3.update_layout(title_text='Clusters Gaussian Mixture 8 clusters', height=400, width=800)\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu77kuH9T64L"
      },
      "source": [
        "Un criterio com√∫n para determinar el n√∫mero √≥ptimo de clusters es el m√©todo del codo, sin embargo, est√° sujeto a la interpretaci√≥n personal. Por lo tanto, una mejor forma de determinar el n√∫mero optimo de clusters es mediante AIC que da cuenta de la calidad del modelo y del BIC tambi√©n da cuenta de la calidad del modelo pero penaliza seg√∫n la cantidad de par√°metros. Entonces podemos encontrar el n√∫mero √≥ptimo de clusters seg√∫n si este minimiza AIC y BIC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXp7azwpY9VL"
      },
      "outputs": [],
      "source": [
        "metrics = pd.DataFrame()\n",
        "metrics['X'] = np.arange(3,9)\n",
        "for cluster in metrics['X']:\n",
        "  metrics.loc[metrics['X']==cluster, 'AIC'] = clusters.loc[0][f'aic_{cluster}']\n",
        "  metrics.loc[metrics['X']==cluster, 'BIC'] = clusters.loc[0][f'bic_{cluster}']\n",
        "\n",
        "px.line(metrics, x='X', y=['AIC', 'BIC'], height=400, width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHbpvWkviy-h"
      },
      "source": [
        "Al observar el gr√°fico, es posible notar que tanto AIC como BIC se minimizan cuando se tienen 8 clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "gunynwf9gZeA",
        "outputId": "a30e004d-3b20-4846-e9e6-c0079ccdd1fe"
      },
      "outputs": [],
      "source": [
        "outliers_pca_gmm_pipe.set_params(gaussian_mix__kw_args={'n_clusters': 8})\n",
        "df_out_gm_8 = outliers_pca_gmm_pipe.fit_transform(df)\n",
        "\n",
        "fig3 = px.scatter(df_out_gm_8, x='pca0',y='pca1',color='cluster')\n",
        "fig3.update_layout(title_text='Clusters Gaussian Mixture 8 clusters', height=400, width=800)\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJPTMTe0nIeO"
      },
      "source": [
        "Debido a la disposici√≥n de los clusters, es dif√≠cil diferenciarlos ya que parecen estar unos sobre otros. El √∫nico cluster que se puede distinguir con claridad es el cluster amarillo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yUMvZRzdo74J",
        "outputId": "43ebe541-6734-4cc4-a77c-7983b11ef5ad"
      },
      "outputs": [],
      "source": [
        "# Descripci√≥n por cluster\n",
        "df_out_gm_8.groupby('cluster').agg({'pca0':['mean','std'], 'pca1':['mean', 'std']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fIKM5hdagtLR"
      },
      "outputs": [],
      "source": [
        "# Proyecci√≥n en 3d\n",
        "outliers_pca_gmm_pipe.set_params(gaussian_mix__kw_args={'n_clusters': 8},pca__n_components=3)\n",
        "df_out_gm_8 = outliers_pca_gmm_pipe.fit_transform(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "5iaKLbFxhWLw",
        "outputId": "55c79dee-d9d3-4051-9228-5a298213ea0f"
      },
      "outputs": [],
      "source": [
        "fig3 = px.scatter_3d(df_out_gm_8, x='pca0',y='pca1', z='pca2',color='cluster')\n",
        "fig3.update_traces(marker=dict(size=3))\n",
        "fig3.update_layout(title_text='Clusters Gaussian Mixture 8 clusters', height=600, width=1000)\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUPX1v2MqqKW"
      },
      "source": [
        "Al graficar los clusters en un espacio 3d, se pueden apreciar claramente la forma de cada uno de ellos, adem√°s tal como se hab√≠a dicho antes, los clusters est√°n unos sobre otros, es por ello que en la representaci√≥n2d no se pod√≠a determinar la forma de cada uno de ellos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
