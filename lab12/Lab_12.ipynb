{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDZmp2BO9KnQ"
   },
   "source": [
    "# **Laboratorio 12: 🚀 Despliegue 🚀**\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>\n",
    "\n",
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdGqUgwX9pGQ"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Carolina Nuñez\n",
    "- Nombre de alumno 2: Alonso Uribe\n",
    "\n",
    "### **Link de repositorio de GitHub:** [Repositorio💻](https://github.com/carinunez/Labs_MDS/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YraSOKrf9yMl"
   },
   "source": [
    "## Temas a tratar\n",
    "\n",
    "- Entrenamiento y registro de modelos usando MLFlow.\n",
    "- Despliegue de modelo usando FastAPI\n",
    "- Containerización del proyecto usando Docker\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Generar una solución a un problema a partir de ML\n",
    "- Desplegar su solución usando MLFlow, FastAPI y Docker\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D98okEzUE8hb"
   },
   "source": [
    "# **Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSiuBfGiFlQM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPn8R-6u877j"
   },
   "source": [
    "\n",
    "\n",
    "Consumida en la tristeza el despido de Renacín, Smapina ha decaído en su desempeño, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria pública de la municipalidad de Maipú se ha contactado con ustedes para que le entreguen una urgente solución a este problema (a la vez que dejan a Smapina, al igual que Renacín, sin trabajo 😔).\n",
    "\n",
    "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de múltiples sensores IOT colocados en diversas cañerías, conductos y estanques. Estos sensores señalan nueve tipos de mediciones químicas y más una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
    "\n",
    "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maipú y su intoxicación podría implicar graves problemas para el cierre del curso.\n",
    "\n",
    "Atributos:\n",
    "\n",
    "1. pH value\n",
    "2. Hardness\n",
    "3. Solids (Total dissolved solids - TDS)\n",
    "4. Chloramines\n",
    "5. Sulfate\n",
    "6. Conductivity\n",
    "7. Organic_carbon\n",
    "8. Trihalomethanes\n",
    "9. Turbidity\n",
    "\n",
    "Variable a predecir:\n",
    "\n",
    "10. Potability (1 si es potable, 0 no potable)\n",
    "\n",
    "Descripción de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aIr6KegWsjS"
   },
   "source": [
    "# **1. Optimización de modelos con Optuna + MLFlow (2.0 puntos)**\n",
    "\n",
    "El objetivo de esta sección es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimización de los hiperparámetros de sus modelos.\n",
    "\n",
    "Como aún no hemos hablado nada sobre `MLFlow` cabe preguntarse: **¡¿Qué !\"#@ es `MLflow`?!**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "## **MLFlow**\n",
    "\n",
    "`MLflow` es una plataforma de código abierto que simplifica la gestión y seguimiento de proyectos de aprendizaje automático. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, además de registrar modelos y controlar versiones.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
    "</p>\n",
    "\n",
    "Si bien esta plataforma cuenta con un gran número de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
    "1. **Runs**: Registro que constituye la información guardada tras la ejecución de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en sí mismo. Dentro de cada `run` podremos acceder a información como los hiperparámetros utilizados, las métricas obtenidas, las librerías requeridas y hasta nos permite descargar el modelo entrenado.\n",
    "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o más `runs`. De esta manera, es posible también registrar métricas, parámetros y archivos (artefactos) asociados a cada experimento.\n",
    "\n",
    "### **Todo bien pero entonces, ¿cómo se usa en la práctica `MLflow`?**\n",
    "\n",
    "Es sencillo! Considerando un problema de machine learning genérico, podemos registrar la información relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
    "\n",
    "```python\n",
    "#!pip install mlflow\n",
    "import mlflow # importar mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "\n",
    "mlflow.autolog() # registrar automáticamente información del entrenamiento\n",
    "with mlflow.start_run(): # delimita inicio y fin del run\n",
    "    # aquí comienza el run\n",
    "    rf.fit(X_train, y_train) # train the model\n",
    "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
    "    # aquí termina el run\n",
    "```\n",
    "\n",
    "Si ustedes ejecutan el código anterior en sus máquinas locales (desde un jupyter notebook por ejemplo) se darán cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el código anterior, se creará otra carpeta y no tendrán acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
    "\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Les dejamos también algunos comandos útiles:\n",
    "\n",
    "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
    "- `mlflow.log_metric(\"nombre_métrica\", métrica)`: Les permite registrar una métrica *custom* bajo el nombre de \"nombre_métrica\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptP_ygr7S04t"
   },
   "source": [
    "## **1.1 Combinando Optuna + MLflow (2.0 puntos)**\n",
    "\n",
    "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **más sabor**. El objetivo de este apartado es simple: automatizar la optimización de los parámetros de nuestros modelos usando `Optuna` y registrando de forma automática cada resultado en `MLFlow`.\n",
    "\n",
    "Considerando el objetivo planteado, se le pide completar la función `optimize_model`, la cual debe:\n",
    "- **Optimizar los hiperparámetros del modelo `XGBoost` usando `Optuna`.**\n",
    "- **Registrar cada entrenamiento en un experimento nuevo**, asegurándose de que la métrica `f1-score` se registre como `\"valid_f1\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
    "- **Guardar los gráficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
    "- **Devolver el mejor modelo** usando la función `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
    "- **Guardar el código en `optimize.py`**. La ejecución de `python optimize.py` debería ejecutar la función `optimize_model`.\n",
    "- **Guardar las versiones de las librerías utilizadas** en el desarrollo.\n",
    "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gráfico dentro de la carpeta `/plots` creada anteriormente.\n",
    "\n",
    "*Hint: Le puede ser útil revisar los parámetros que recibe `mlflow.start_run`*\n",
    "\n",
    "```python\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
    "\n",
    "    return best_model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow\n",
    "# pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import optuna\n",
    "# con el submodulo de matplotlib, es más rapida la descarga de archivos\n",
    "from optuna.visualization.matplotlib import (plot_optimization_history, plot_param_importances, \n",
    "                                    plot_parallel_coordinate)\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('water_potability.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Info dataset')\n",
    "print('\\nShape: ', data.shape)\n",
    "print('\\nInfo:')\n",
    "print(data.info())\n",
    "print('\\n Valores nulos \\n')\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviso comportamiento de las variables\n",
    "axes = data.hist(figsize=(18, 8));\n",
    "for ax in axes.flatten():\n",
    "    ax.set_title(ax.get_title(), fontsize=10)\n",
    "    ax.tick_params(axis='x', labelsize=6)\n",
    "    ax.tick_params(axis='y', labelsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las variables parecen comportarse de manera gaussiana, se reemplazarán los valores nulos por la media de las variables, para evitar afectar la distribución de estas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nan = data.columns[data.isna().any()].tolist()\n",
    "for col in col_nan:\n",
    "    data.fillna({col: data[col].mean()}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "X = data.drop(columns='Potability').copy()\n",
    "y = data.Potability.copy()\n",
    "\n",
    "def fillna_df(df):\n",
    "    for col in df.columns:\n",
    "        df.fillna({col: df[col].mean()}, inplace=True)\n",
    "    return df\n",
    "\n",
    "cols_nan = X.columns[X.isna().any()].tolist()\n",
    "standard_sc = ColumnTransformer([\n",
    "                ('fillna', FunctionTransformer(fillna_df), cols_nan),\n",
    "                ('standard', StandardScaler(), X.columns)])\n",
    "X = standard_sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "# transformer = DropConstantFeatures(tol=0.8)\n",
    "# transformer.fit_transform(X_train)\n",
    "\n",
    "# transformer.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "# corr_identifier = SmartCorrelatedSelection(\n",
    "#     variables=None,\n",
    "#     method=\"pearson\",\n",
    "#     threshold=0.8,\n",
    "#     selection_method=\"variance\",\n",
    "#     estimator=None,\n",
    "# )\n",
    "\n",
    "# corr_identifier.fit_transform(X_train)\n",
    "# print('correlacionadas: ',corr_identifier.correlated_feature_sets_)\n",
    "# print('variable retenida: ', corr_identifier.correlated_feature_dict_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando una tolerancia de 0.8, es posible decir que ninguna variable se puede considerar constante o quasiconstante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install optuna\n",
    "# !pip install optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_function(trial):\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                                            X, y, test_size=0.3, random_state=29, \n",
    "                                            shuffle=True)\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    xgb_params = {\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            'max_leaves': trial.suggest_int(\"max_leaves\", 3, 30),\n",
    "            \"grow_policy\": trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "\n",
    "            \"n_jobs\": trial.suggest_int('n_jobs', 1, 3),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 7),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        }\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(seed=29, **xgb_params)\n",
    "    model.fit( X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)],)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    yhat = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, yhat, average='weighted')\n",
    "   \n",
    "    run_name = f\"XGB_con_lr_{xgb_params['learning_rate']:.5f}_n_estimators_{xgb_params['n_estimators']}\\\n",
    "                _Mdepth_{xgb_params['max_depth']}_Mleaves_{xgb_params['max_leaves']}\"\n",
    "    \n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # cargo los parametros y metricas a mlflow \n",
    "        mlflow.log_params(xgb_params)\n",
    "        mlflow.log_metric('valid_f1', f1)\n",
    "\n",
    "        os.makedirs('plots', exist_ok=True)\n",
    "        # optimization_history\n",
    "        opti_history = plot_optimization_history(study)#.write_html('plots/opti_history.html')\n",
    "\n",
    "        # parallel coordinate \n",
    "        parallel = plot_parallel_coordinate(study)#.write_html('plots/parallel_coordinate.html')\n",
    "\n",
    "        # params importances\n",
    "        importances = plot_parallel_coordinate(study)#.write_html('plots/params_importances.html')\n",
    "        \n",
    "        # subo la carpeta plots (local) completa a mlflow\n",
    "        mlflow.log_artifacts('plots', artifact_path='plots')\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Devolver el mejor modelo** usando la función `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
    "- **Guardar el código en `optimize.py`**. La ejecución de `python optimize.py` debería ejecutar la función `optimize_model`.\n",
    "- **Guardar las versiones de las librerías utilizadas** en el desarrollo.\n",
    "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gráfico dentro de la carpeta `/plots` creada anteriormente.\n",
    "\n",
    "*Hint: Le puede ser útil revisar los parámetros que recibe `mlflow.start_run`*\n",
    "\n",
    "```python\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
    "\n",
    "    return best_model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    exp_name='XGBClassifier'\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    \n",
    "    study = optuna.create_study( direction=\"maximize\")\n",
    "    study.optimize(objective_function, n_trials=10, show_progress_bar=True)\n",
    "    \n",
    "    best_model = study.best_trial.params\n",
    "    print('Best model params:', best_model)\n",
    "\n",
    "    \n",
    "    # Save best model to file\n",
    "    \n",
    "    # with open('.models/best_model.pkl', 'wb') as file:\n",
    "    #     pickle.dump(best_model, file)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros del mejor modelo\n",
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devolver el mejor modelo** usando la función `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_id)\n",
    "best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [01:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts:\n##### File model #####\nAPI request to http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts/model failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts/model (Caused by ResponseError('too many 500 error responses'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns:/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_model_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caron\\.conda\\envs\\labs_env\\lib\\site-packages\\mlflow\\xgboost\\__init__.py:337\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, dst_path)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_uri, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an XGBoost model from a local file or a run.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m        models, depending on the saved model class specification.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     flavor_conf \u001b[38;5;241m=\u001b[39m _get_flavor_configuration(local_model_path, FLAVOR_NAME)\n\u001b[0;32m    339\u001b[0m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "File \u001b[1;32mc:\\Users\\caron\\.conda\\envs\\labs_env\\lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:116\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[0;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caron\\.conda\\envs\\labs_env\\lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:131\u001b[0m, in \u001b[0;36mRunsArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, artifact_path, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Download an artifact file or directory to a local directory if applicable, and return a\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    local path for it.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        Absolute path of the local filesystem location containing the desired artifacts.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caron\\.conda\\envs\\labs_env\\lib\\site-packages\\mlflow\\store\\artifact\\artifact_repo.py:302\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m    296\u001b[0m         template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### File \u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m #####\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{error}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    299\u001b[0m         template\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath, error\u001b[38;5;241m=\u001b[39merror, traceback\u001b[38;5;241m=\u001b[39mtracebacks[path])\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m path, error \u001b[38;5;129;01min\u001b[39;00m failed_downloads\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    301\u001b[0m     )\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    303\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following failures occurred while downloading one or more\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m artifacts from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_truncate_error(failures)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         )\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_path, artifact_path)\n",
      "\u001b[1;31mMlflowException\u001b[0m: The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts:\n##### File model #####\nAPI request to http://127.0.0.1:5000/api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts/model failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/296378185328108389/e6eeeb61a07e4b789a7b81e2d5995629/artifacts/model (Caused by ResponseError('too many 500 error responses'))"
     ]
    }
   ],
   "source": [
    "mlflow.xgboost.load_model(\"runs:/\" + best_model_id + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca el id del experimento según su nombre\n",
    "def search_id(exp_name):\n",
    "    return dict(mlflow.get_experiment_by_name(exp_name))['experiment_id']\n",
    "\n",
    "serch_id(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = serch_id(experiment_name)\n",
    "get_best_model(exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  **Devolver el mejor modelo** usando la función `get_best_model` y\n",
    "#  serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar las versiones de las librerías utilizadas** en el desarrollo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respalde las configuraciones del modelo final y la importancia de las variables** en un gráfico dentro de la carpeta `/plots` creada anteriormente.\n",
    "\n",
    "# *Hint: Le puede ser útil revisar los parámetros que recibe `mlflow.start_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL2iG18289j9"
   },
   "source": [
    "# **2. FastAPI (2.0 puntos)**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "Con el modelo ya entrenado, la idea de esta sección es generar una API REST a la cual se le pueda hacer *requests* para así interactuar con su modelo. En particular, se le pide:\n",
    "\n",
    "- Guardar el código de esta sección en el archivo `main.py`. Note que ejecutar `python main.py` debería levantar el servidor en el puerto por defecto.\n",
    "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
    "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medición de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"ph\":10.316400384553162,\n",
    "   \"Hardness\":217.2668424334475,\n",
    "   \"Solids\":10676.508475429378,\n",
    "   \"Chloramines\":3.445514571005745,\n",
    "   \"Sulfate\":397.7549459751925,\n",
    "   \"Conductivity\":492.20647361771086,\n",
    "   \"Organic_carbon\":12.812732207582542,\n",
    "   \"Trihalomethanes\":72.28192021570328,\n",
    "   \"Turbidity\":3.4073494284238364\n",
    "}\n",
    "```\n",
    "\n",
    "Su servidor debería retornar una respuesta HTML con código 200 con:\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"potabilidad\": 0 # respuesta puede variar según el clasificador que entrenen\n",
    "}\n",
    "```\n",
    "\n",
    "**`HINT:` Recuerde que puede utilizar [http://localhost:8000/docs](http://localhost:8000/docs) para hacer un `POST`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSausqDJ9CQh"
   },
   "source": [
    "# **3. Docker (2 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNmC483flS00"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niMA_qsCjqlv"
   },
   "source": [
    "Tras el éxito de su aplicación web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
    "\n",
    "## **3.1 Creación de Container (1 punto)**\n",
    "\n",
    "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el código fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicación. Para la dockerización, asegúrese de cumplir con los siguientes puntos:\n",
    "\n",
    "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
    "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
    "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
    "4. **Incluir imágenes en el notebook** que muestren la ejecución del contenedor y los resultados obtenidos.\n",
    "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en términos de recursos.\n",
    "\n",
    "## **3.2 Preguntas de Smapina (1 punto)**\n",
    "Tras haber experimentado con Docker, Smapina desea profundizar más en el tema y decide realizarle las siguientes consultas:\n",
    "\n",
    "- ¿Cómo se diferencia Docker de una máquina virtual (VM)?\n",
    "- ¿Cuál es la diferencia entre usar Docker y ejecutar la aplicación directamente en el sistema local?\n",
    "- ¿Cómo asegura Docker la consistencia entre diferentes entornos de desarrollo y producción?\n",
    "- ¿Cómo se gestionan los volúmenes en Docker para la persistencia de datos?\n",
    "- ¿Qué son Dockerfile y docker-compose.yml, y cuál es su propósito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GwP2aLT9C1l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xJ_ZK1IfnZW"
   },
   "source": [
    "# Conclusión\n",
    "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.pinimg.com/originals/84/5d/f1/845df1aefc6a5e37ae575327a0cc6e43.gif\" width=\"500\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
