{"cells":[{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"3babcb21b0cd478db265bdaf6e57484f","deepnote_cell_type":"markdown"},"source":"![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)","block_group":"97a925d0feb747c98c04ad1f0769c370"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"cb846764c97a4451bb80bc9aef856433","deepnote_cell_type":"markdown"},"source":"# De las Comisiones a la Innovación: El Giro de Ignacio Yacurro\n\n**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n\n### Cuerpo Docente:\n\n- Profesor: Sebastián Tinoco, Ignacio Meza De La Jara\n- Auxiliar: Eduardo Moya Briones\n- Ayudante: Nicolás Ojeda González, Melanie Peña Torres, Valentina Rojas Osorio\n\n_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n\n---","block_group":"54441f65ac154a3bbfb9fa568961fd2b"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"949afd70f726401995c3381100bbe08f","deepnote_cell_type":"markdown"},"source":"## **Reglas**\n- El proyecto consta de 2 entregas parciales y una entrega final, con las siguiente fechas de entrega:\n    - **Entrega Parcial 1**: del 13 al 28 de Noviembre del 2024 \n    - **Entrega Parcial 2**: del 29 de Noviembre al 5 de Diciembre del 2024  \n    - **Entrega Final**: del 6 al 12 de Diciembre del 2024\n    - **Revisión de Pares**: del 13 al 14 de Diciembre del 2024\n\n- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n- Estrictamente prohibida la copia.\n- Pueden usar cualquier material del curso que estimen conveniente.\n- Hay BONUS para los equipos que tengan los mejores resultados en la competencia. \n- **Grupos de 2 personas.**\n- <u>Por cada entrega que no suban a CodaLab, se descontará 1 punto de su nota final.</u>\n\n### Entregables:\n\n- **Informe Final:** En la entrega final, deberán incluir un informe que abarque **todo** su trabajo realizado en esta y en iteraciones anteriores. Se recomienda ir escribiendo el informe en paralelo a la creación de los modelos.\n  \n- **Datos Disponibles:** Para la fase actual, tienen a su disposición los datos bancarios de las fases 1 y 2 (**$X_{t0}$**, **$y_{t0}$**, **$X_{t1}$**, **$y_{t1}$**, **$X_{t2}$**) más **$y_{t2}$**. Noten que el conjunto **($X_{t2}$, $y_{t2}$)** contiene los datos etiquetados de la segunda entrega a CodaLab + una porción de datos nuevos, por lo que **deben descargar nuevamente los datos.** \n\n- **Entrega de Predicciones:** Suban las predicciones de su último modelo a la última fase de la competencia, utilice para las predicciones el archivo $X_{t3}$. **Revisen las fechas de cierre de la competencia en Codalab.**\n\n- **Peer Review:** Cada grupo deberá preparar un video donde presenten sus proyectos, con una **duración máxima de 5 minutos**. Este video deberá incluir como mínimo los siguientes puntos:\n    - Introducción: Contexto, objetivos del proyecto, datos utilizados, etc.\n    - Metodología: Expliquen a grandes rasgos el preprocesamiento, los modelos y métodos utilizados para los entrenamientos, interpretabilidad, despliegue, etc.\n    - Resultados: Principales hallazgos, métricas, análisis, etc.\n    - Conclusiones: Observaciones y reflexiones sobre los datos, la problemática, los modelos utilizados, herramientas utilizadas y limitaciones.\n\n    Se le recuerda que cada grupo deberá evaluar el proyecto de 2 grupos distintos del curso y la evaluación recibida tendrá un peso específico en la calificación final del proyecto.","block_group":"8c80e868ff844c0cb8921511d967a6f9"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"5e1d2e61c1ca46f7ab120787bb3fc576","deepnote_cell_type":"markdown"},"source":"## Notas adicionales\n- No necesitan tener un rendimiento cercano al 100% para tener una resolución exitosa en el proyecto.\n- Utilizar paralelización para acelerar búsquedas. Esto podría ser una buena solución para el caso de que la búsqueda de hiperparámetros sea muy lenta. En caso de tener problemas de RAM, reducir la cantidad de `jobs` a algo que su computador/interprete web pueda procesar.\n- Generar grillas de búsquedas razonables. Entre más grande es la grilla, más lento el proceso de búsqueda. Utilice grillas de tamaños adecuados para que la búsqueda converga en tiempos razonables y no se demore 3.5 eternidades en terminar.","block_group":"862616063a5d4ff09ad19365f477a3cd"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"e1163811f4f0482f9c382ea638e9ede5","deepnote_cell_type":"markdown"},"source":"## Link Competencia [CodaLab](https://codalab.lisn.upsaclay.fr/competitions/20705?secret_key=802a6a25-9a8c-4821-a68e-3d8c02adcd82)\nAcuerdese de utilizar el archivo correspondiente para hacer la entrega de resultados a la competencia. Utilizar los datos equivocados se va a ver reflejado en un bajo desempeño en la tabla de resultados.\n\n## Fuentes de Datos [GitLab](https://gitlab.com/mds7202-2/proyecto-mds7202)\n\nA través de **GitLab** se dispondrán de las fuentes de datos a utilizar en cada una de las etapas del proyecto. Los datos se encuentran en la carpeta _**competition_files**_. Estos serán actualizados en cada etapa del proyecto dentro de la misma carpeta.\n\nAdicionalmente, para esta etapa se dispondrán de los mismos datos con el nombre formateado en la fecha de subida, los cuales serán necesarios para las secciones a abordar en esta etapa del proyecto. Estos se encuentran en la carpeta _**production_stage_files**_ disponibles en el siguiente enlace: [https://gitlab.com/mds7202-2/proyecto-mds7202/-/tree/main/production_stage_files](https://gitlab.com/mds7202-2/proyecto-mds7202/-/tree/main/production_stage_files)\n\nLas descripciones de cada uno de los atributos del dataset a utilizar se encuentran disponibles en la competencia de **CodaLab**, en la pestaña _**Participate**_ y en el apartado _**Get Data**_.  ","block_group":"1d6cd78b31764f09b129fef8717a3650"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"3e2357528c204b948d9337793c2b7cf8","deepnote_cell_type":"markdown"},"source":"# **Entrega Final**","block_group":"594a95c7c27f4108b3535984992e7319"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"22f2086e5f7840a383cc48469ef740cc","deepnote_cell_type":"markdown"},"source":"## **Puntos a Desarrollar:**\n\nA continuación se describen las tareas a desarrollar en la presente fase.\n","block_group":"8d0ce1c2df674efab2a3216968fa4adf"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"8ad4f2f2d0b441498f8e90cbf7b336c2","deepnote_cell_type":"markdown"},"source":"#### Monitoreo\n\nEl objetivo de este paso es comprender la importancia de medir la consistencia de los datos y el desempeño de los modelos. Esta práctica permite evitar potenciales problemas durante los pasos a producción, por lo que se debe observar constantemente los modelos en funcionamiento.\n\n- Implementar un sistema de monitoreo que permita verificar si existe data-drift entre los datos iniciales y los nuevos datos entregados. Proponer un método basándose en la clase de monitoreo, fundamentando la decisión.\n- Evaluación constante del rendimiento de los modelos en producción para detectar posibles desviaciones y anomalías.\n\n#### Canalizaciones Productivas\nPara optimizar y automatizar nuestro flujo de trabajo, se implementará una canalización productiva utilizando Apache Airflow, encargada de monitorizar, detectar y gestionar automáticamente cualquier indicio de data drift en los datos de entrada. Esta canalización incluirá componentes para:\n\n1. **Extracción de datos:** Recolección de datos desde las fuentes correspondientes ([GitLab](https://gitlab.com/mds7202-2/proyecto-mds7202/-/tree/main/production_stage_files)). Note que los archivos corresponden a los conjuntos ($X_t0$, $y_t0$), ($X_t1$, $y_t1$), ($X_t2$, $y_t2$), con la fecha de disponibilidad en el nombre.\n2. **Limpieza y transformación:** Asegurar la calidad y consistencia de los datos.\n3. **Análisis de data drift:** Comparación de los datos de entrada con el conjunto de datos original para detectar desviaciones.\n4. **Reentrenamiento del modelo y optimización:** En caso de detectarse data drift, la canalización iniciará automáticamente el reentrenamiento del modelo con los nuevos datos.\n5. **Tracking de Interpretabilidad**: Guardar y registrar las figuras generadas a partir del análisis de interpretabilidad generado (SHAP, Anchors, etc.).\n\nPara esta sección se espera que usen el código generado en la Entrega Parcial 2. Por lo mismo, es imperativo que su solución consolide al menos las siguientes librerías:\n- Apache Airflow\n- Optuna\n- SHAP\n- MLFlow\n\nSe validará y evaluará el rendimiento del nuevo modelo antes de su implementación, asegurando que se mantenga la precisión y relevancia del modelo en producción. Además, los modelos entrenados y los resultados de las evaluaciones se guardarán y registrarán para futuros análisis.\n\nDebido a que los datos potencialmente se actualizarán semana a semana, el pipeline tendrá un intervalo de ejecución semanal. Por ello, debe ser capaz de identificar si existen nuevos datos para descargar, lo que gatillará la ejecución de la detección de data drift y el posterior reentrenamiento (si es necesario).\n\nCon el motivo de generar un monitoreo sobre cada uno de los pasos que tendrá su canalización, se generará una pipeline atomizada e idempotente. Por otro lado, para simular procesos o datos anteriores, su pipeline deberá ejecutarse para todas las fechas anteriores y debe ser coherente con la fecha que aparece en el nombre de cada archivo.\n\n**Hint:** Notar la fecha inicio de los archivos, estos podrían denotar una fecha relevante.\n","block_group":"14002ee1d0ca46e990244d86a7490574"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"18da6a27b745462b81bff681786d8f88","deepnote_cell_type":"markdown"},"source":"# Estructura del Informe\n\nDe acuerdo con lo señalado en entregas previas, el equipo debe presentar un informe siguiendo la estructura detallada a continuación:\n\n## **1. Introducción [0.25 puntos]**\n\nEsta sección debe incluir:  \n- Una descripción breve del problema planteado: ¿Qué se busca predecir?  \n- Un resumen de los datos de entrada proporcionados.  \n- La métrica seleccionada para evaluar los modelos, con su respectiva justificación. Dado que los datos están desbalanceados, se recomienda evitar el uso de `accuracy` y centrarse en métricas como `precision`, `recall` o `f1-score`, especificando la clase de interés.  \n- Una mención breve de los modelos empleados para abordar el problema, incluyendo las transformaciones intermedias aplicadas a los datos.  \n- Un análisis general de los resultados obtenidos, señalando si el modelo final cumplió con los objetivos planteados y cómo se posicionó frente a los de otros equipos.\n\n## **2. Preprocesamiento [0.75 puntos]**\n\n### **2.1 Análisis Exploratorio de Datos [0.5 puntos]**\n\nSe debe realizar un análisis detallado para identificar patrones, tendencias y relaciones en los datos. Este análisis permitirá una mejor comprensión de las características del conjunto de datos y guiará las decisiones en el pipeline de modelamiento.\n\nSe deben incluir:  \n- Estadísticas descriptivas generales.  \n- Visualizaciones para detectar distribuciones, valores atípicos y relaciones entre variables.  \n- Observaciones relevantes que puedan influir en las etapas posteriores del proyecto.  \n\nEl análisis debe presentarse de manera profesional, demostrando tanto la implementación técnica como una comprensión profunda del problema y los datos.\n\n### **2.2 Preprocesamiento de Datos [0.25 puntos]**\n\nSe deben aplicar técnicas de preprocesamiento que garanticen la calidad y adecuación de los datos para el modelamiento. Algunas tareas recomendadas son:  \n- Estandarización de filas y/o columnas.  \n- Reducción de dimensionalidad.  \n- Discretización de variables numéricas a categóricas.  \n- Manejo de valores nulos.  \n- Otras transformaciones pertinentes según las características del conjunto de datos.  \n\nEsta sección debe enfocarse en la limpieza y preparación de los datos para su uso en el entrenamiento y evaluación de los modelos. Es fundamental realizar un **`train_test_split`** para dividir los datos en conjuntos de entrenamiento y validación siguiendo una proporción adecuada (por ejemplo, 70/30).\n\nSe espera implementar las siguientes técnicas:  \n- **Uso de `ColumnTransformer`:** Aplicar transformaciones específicas a distintas columnas.  \n- **Imputación de valores nulos:** Seleccionar una estrategia apropiada (media, mediana, moda, etc.) para completar datos faltantes.  \n- **Discretización de variables:** Convertir variables continuas en categóricas cuando sea beneficioso para el modelo.  \n- **Estandarización o normalización:** Mejorar el rendimiento de algoritmos sensibles a la escala de los datos.  \n- Otras transformaciones relevantes en función de las características de los datos.\n\nSe deben documentar y justificar cada decisión en el informe, vinculando las elecciones con los objetivos del proyecto.\n\n## **3. Modelamiento [1.75 puntos]**\n\n### **3.1 Baseline [0.25 puntos]**\n\nSe debe implementar una técnica **Hold-Out**, dividiendo los datos en **70% para entrenamiento** y **30% para prueba**.\n\n**Creación de un modelo baseline:**  \nEl equipo debe entrenar un modelo básico que sirva como referencia para evaluar los modelos más avanzados.\n\nEsta sección requiere construir el modelo más sencillo posible, conocido como **modelo baseline**, que servirá como punto de referencia para comparar el rendimiento de los modelos posteriores.  \n\nPasos requeridos:  \n- Implementar, entrenar y evaluar un modelo básico utilizando un pipeline.  \n- Incluir en el pipeline las transformaciones realizadas previamente junto con un clasificador básico.  \n- Evaluar el modelo utilizando **`classification_report`** y documentar las métricas obtenidas.  \n\nEs necesario documentar claramente cómo se creó el modelo, las decisiones tomadas y los resultados, ya que este será la base comparativa.\n\n### **3.2 Modelos de Machine Learning [0.5 puntos]**\n\n- Se deben utilizar exclusivamente pipelines de **Scikit-Learn** para esta iteración del proyecto.  \n- El uso de librerías o herramientas externas será penalizado con una calificación de **0** en las secciones implicadas.  \n\nSe deben desarrollar tres modelos avanzados, cada uno integrado en un pipeline que combine el preprocesamiento con un clasificador.  \n\nSe debe incluir:  \n- **Estructura y diferencias:** Describir los clasificadores seleccionados, sus hiperparámetros iniciales y el enfoque adoptado.  \n- **Resultados:** Evaluar cada modelo utilizando **`classification_report`**, destacando métricas como precisión, recall y f1-score.  \n- **Clasificadores sugeridos:**  \n  - `LogisticRegression`  \n  - `KNeighborsClassifier`  \n  - `DecisionTreeClassifier`  \n  - `SVC`  \n  - `RandomForestClassifier`  \n  - `LightGBMClassifier` (`lightgbm`)  \n  - `XGBClassifier` (`xgboost`)  \n  - Otros.  \n\nSe deben responder las siguientes preguntas:  \n1. ¿Algún clasificador supera al modelo baseline?  \n2. ¿Cuál es el mejor clasificador entrenado y por qué?  \n3. ¿Qué factores explican la superioridad del mejor clasificador?  \n4. ¿Qué modelo es más eficiente para realizar optimizaciones en términos de tiempo de entrenamiento?  \n\nFinalmente, se debe seleccionar **uno de los tres modelos** para las siguientes secciones y justificar su elección.\n\n### **3.3 Optimización de Modelos [0.5 puntos]**\n\nSe debe optimizar el modelo seleccionado implementando técnicas de ajuste de hiperparámetros, como `Optuna`.  \n\nSe deben responder:  \n- ¿Qué métrica se decidió optimizar y por qué?  \n- ¿Cuánto tiempo se dedicó a esta etapa? ¿Podrían lograrse mejores resultados invirtiendo más tiempo?  \n- ¿Qué hiperparámetro tuvo mayor impacto en el rendimiento del modelo?  \n\nSe deben incluir mejoras como selección de atributos o ajustes en el imputador de datos y explicar cómo estas decisiones influyen en el rendimiento.\n\n### **3.4 Interpretabilidad [0.5 puntos]**\n\nSe debe explicar el funcionamiento del modelo utilizando herramientas de interpretabilidad como `SHAP` o `Anchors`.  \n\nSe debe incluir:  \n- Justificaciones para tres predicciones concretas.  \n- Identificación del atributo más relevante para las predicciones y su relación con el problema.  \n- Posibles sesgos hacia atributos específicos y su mitigación.  \n\nEl informe debe demostrar cómo estas herramientas permiten interpretar los resultados del modelo y tomar decisiones fundamentadas.\n\n## **4. MLOps [2.5 puntos]**\n\n### **4.1 Tracking con MLFlow [0.6 puntos]**\n\nDurante el proceso de modelamiento, se debe realizar un seguimiento detallado de los elementos generados, incluyendo métricas de desempeño, modelos, hiperparámetros, optimización, interpretabilidad, entre otros.\n\nRequisitos:  \n- Configurar MLFlow para rastrear experimentos, entrenamientos y versiones de los modelos.  \n- Documentar el seguimiento de los pasos clave del pipeline.  \n\nSe deben presentar los resultados del tracking implementado, destacando elementos como métricas de desempeño, hiperparámetros utilizados y análisis de optimización.  \nPara guiarse, se puede consultar el [quickstart guide de MLFlow](https://mlflow.org/docs/latest/tracking.html#quickstart).\n\n**Nota:** Se deben asignar nombres descriptivos a los experimentos para facilitar su identificación y análisis.\n\n### **4.2 Desarrollo de Aplicación Web [0.6 puntos]**\n\nEl equipo debe desarrollar una aplicación web que facilite la consulta del producto final por parte del cliente. Para ello, se deben cumplir los siguientes requisitos:\n\n- **Frontend con Gradio:** Crear una interfaz amigable e intuitiva para realizar predicciones.  \n- **Backend con FastAPI:** Implementar la lógica de inferencia del modelo en el backend.  \n- **Entrada de datos:**  \n  - La aplicación debe permitir dos métodos de entrada:  \n    1. Carga de un archivo `.csv`.  \n    2. Ingreso manual mediante un formulario.  \n  - Ambos métodos deben estar habilitados, pero el usuario deberá elegir uno para realizar la predicción.  \n- **Dockerización:** Tanto el backend como el frontend deben estar dockerizados para garantizar portabilidad, escalabilidad y despliegue eficiente en diferentes entornos.\n\nEl equipo debe asegurar que la comunicación entre backend y frontend permita una experiencia fluida para el usuario.  \nPara guiarse, pueden consultar la [cheatsheet de DockerLabs](https://dockerlabs.collabnix.com/docker/cheatsheet/).\n\n### **4.3 Monitoreo [0.3 puntos]**\n\nEl equipo debe implementar un sistema de monitoreo para garantizar la consistencia de los datos y el desempeño del modelo en producción. Esto incluye:\n\n- **Data drift:** Desarrollar un método para detectar diferencias significativas entre los nuevos datos y los datos originales.  \n- **Evaluación continua:** Supervisar el rendimiento del modelo en producción para identificar desviaciones y anomalías.\n\nSe deben responder las siguientes preguntas:  \n- ¿Se detecta data drift? ¿Cómo se abordará?  \n- ¿Qué sucede si los datos nuevos son más desbalanceados?  \n\nAdemás, se deben justificar las decisiones tomadas para manejar estas situaciones.\n\n### **4.4 Canalizaciones Productivas [1.0 puntos]**\n\nEl equipo debe diseñar e implementar una canalización productiva utilizando **Apache Airflow** para automatizar y optimizar el flujo de trabajo. Esta canalización debe incluir:\n\n1. **Extracción de datos:** Recolectar datos desde las fuentes definidas (por ejemplo, GitLab).  \n2. **Limpieza y transformación:** Garantizar la calidad y consistencia de los datos.  \n3. **Análisis de data drift:** Comparar los datos nuevos con el conjunto original para detectar desviaciones significativas.  \n4. **Reentrenamiento del modelo:** Activar automáticamente el reentrenamiento si se detecta data drift.  \n5. **Tracking de interpretabilidad:** Registrar y guardar figuras generadas por herramientas como SHAP.\n\nEl equipo debe integrar las siguientes librerías: **Apache Airflow**, **Optuna**, **SHAP** y **MLFlow**.  \nSe debe presentar:\n\n- Una descripción del **DAG** del pipeline, explicando la funcionalidad de cada tarea y la relación entre ellas.  \n- Una representación visual del **DAG** con ejemplos de ejecución para distintas fechas.  \n- Una explicación de los beneficios de una canalización atomizada e idempotente.  \n\n## **5. Resultados [0.5 puntos]**\n\nEl equipo debe documentar los resultados obtenidos a lo largo de las iteraciones del proyecto, considerando que habrá al menos tres ciclos de entrenamiento. Se debe analizar cómo cambiaron los resultados a medida que se ajustaron los modelos y estrategias.\n\nPreguntas a responder:  \n- ¿Cuál fue el rendimiento de los modelos para abordar el problema?  \n- ¿Qué significan estos resultados en términos prácticos?  \n- ¿Cómo evolucionaron los resultados a lo largo de las iteraciones?  \n- ¿Qué fenómenos o hiperparámetros podrían explicar gran parte de los resultados obtenidos?  \n- ¿Qué factores contribuyeron al overfitting o underfitting y cómo influyeron en la elección del mejor modelo?\n\nEl análisis debe ser exhaustivo, explicando los resultados desde un punto de vista técnico y metodológico.\n\n## **6. Conclusiones [0.25 puntos]**\n\nEl equipo debe sintetizar los hallazgos del proyecto, conectando todas las secciones del informe desde la Introducción hasta los Resultados. Las conclusiones deben incluir:\n\n- Identificación de los modelos con mejor desempeño.  \n- Observaciones generales sobre los datos y la problemática.  \n- Reflexiones sobre las herramientas y técnicas utilizadas, destacando su utilidad y limitaciones.  \n\nEl cierre debe proporcionar una visión global del proyecto, destacando las decisiones clave tomadas durante su desarrollo y su impacto en los resultados obtenidos.","block_group":"169681cfd49141068dda46ec35811cb1"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"ec967c3e6d824f2f8711a3f478a9d884","deepnote_cell_type":"markdown"},"source":"## **Recordatorio**\n\nLa última entrega requiere la presentación de un informe completo más sus resultados finales en CodaLab. Adicionalmentre, deben subir su video de presentación del proyecto.","block_group":"c929a510d7794573808cb5725e09d797"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_app_layout":"powerful-article","deepnote_app_reactivity_enabled":true,"deepnote_notebook_id":"3c75531af9884d01aed2d1cf8d06175a"}}