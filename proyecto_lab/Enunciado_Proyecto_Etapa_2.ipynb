{"cells":[{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"516acf1d6e9d4ddb9a8acdeb6b1cca14","deepnote_cell_type":"markdown"},"source":"![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)","block_group":"70a0f1152563497dba19cb9a3d9ffef7"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"befdb70375f04ab79952117eb63723e7","deepnote_cell_type":"markdown"},"source":"# De las Comisiones a la Innovación: El Giro de Ignacio Yacurro\n\n**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n\n### Cuerpo Docente:\n\n- Profesor: Sebastián Tinoco, Ignacio Meza De La Jara\n- Auxiliar: Eduardo Moya Briones\n- Ayudante: Nicolás Ojeda González, Melanie Peña Torres, Valentina Rojas Osorio\n\n_Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir._\n\n---","block_group":"d5959ecb032949b486b8289fd8ac1f5d"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"e38a0c399b794718916b5eb2d04e0d91","deepnote_cell_type":"markdown"},"source":"## **Reglas**\n- El proyecto consta de 2 entregas parciales y una entrega final, con las siguiente fechas de entrega:\n    - **Entrega Parcial 1**: del 13 al 28 de Noviembre del 2024 \n    - **Entrega Parcial 2**: del 29 de Noviembre al 5 de Diciembre del 2024  \n    - **Entrega Final**: del 6 al 12 de Diciembre del 2024\n    - **Revisión de Pares**: del 13 al 14 de Diciembre del 2024\n\n- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n- Estrictamente prohibida la copia.\n- Pueden usar cualquier material del curso que estimen conveniente.\n- Hay BONUS para los equipos que tengan los mejores resultados en la competencia. \n- **Grupos de 2 personas.**\n- <u>Por cada entrega que no suban a CodaLab, se descontará 1 punto de su nota final.</u>\n\n* Entregables:\n    * Para la fase actual, tienen a su disposición los datos bancarios de la fase 1 (**X_t0.parquet**, **y_t0.parquet** y **X_t1.parquet**) más **y_t1.csv**. Tendrán que hacer las predicciones sobre el set de datos **X_t2.parquet**\n    * Noten que el conjunto **(X_1.parquet, y_t1.parquet)** contiene los datos etiquetados de la primera entrega a CodaLab + una porción de datos nuevos, por lo que **deben descargar nuevamente los datos.** \n    * En cada entrega deben subir, al menos,un modelo y predecir el conjunto de datos de prueba (**X_t2.csv**) para reportar sus resultados en la competencia en CodaLab. Para esto, utilizar la función ``generateFiles`` que se encuentra en Anexos. **Esta genera el archivo a entregar en la competencia, no modificar.**\n    * En la entrega final, deberán incluir un informe que abarque todo su trabajo realizado. Se recomienda ir escribiendo el informe en paralelo a la creación de los modelos.","block_group":"0ea9c925822246c99b6d710b0313bdc6"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"ad10b0086d0241a3b3063e36555d6b9f","deepnote_cell_type":"markdown"},"source":"## Notas adicionales\n- No necesitan tener un rendimiento cercano al 100% para tener una resolución exitosa en el proyecto.\n- Utilizar paralelización para acelerar búsquedas. Esto podría ser una buena solución para el caso de que la búsqueda de hiperparámetros sea muy lenta. En caso de tener problemas de RAM, reducir la cantidad de `jobs` a algo que su computador/interprete web pueda procesar.\n- Generar grillas de búsquedas razonables. Entre más grande es la grilla, más lento el proceso de búsqueda. Utilice grillas de tamaños adecuados para que la búsqueda converga en tiempos razonables y no se demore 3.5 eternidades en terminar.","block_group":"24c6f53b47ec47e495f167ef72296281"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"7ec32a4d74444100aa91bad37b7e8319","deepnote_cell_type":"markdown"},"source":"## Link Competencia [CodaLab](https://codalab.lisn.upsaclay.fr/competitions/20705?secret_key=802a6a25-9a8c-4821-a68e-3d8c02adcd82)\nAcuerdese de utilizar el archivo correspondiente para hacer la entrega de resultados a la competencia. Utilizar los datos equivocados se va a ver reflejado en un bajo desempeño en la tabla de resultados.\n\n## Fuentes de Datos [GitLab](https://gitlab.com/mds7202-2/proyecto-mds7202)\n\nA través de **GitLab** se dispondrán de las fuentes de datos a utilizar en cada una de las etapas del proyecto. Los datos se encuentran en la carpeta _**competition_files**_. Estos serán actualizados en cada etapa del proyecto dentro de la misma carpeta.\n\nLas descripciones de cada uno de los atributos del dataset a utilizar se encuentran disponibles en la competencia de **CodaLab**, en la pestaña _**Participate**_ y en el apartado _**Get Data**_.  ","block_group":"2787d3541e434e388a41524ae607f167"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"73dd6ad576224431b010e7650d06156e","deepnote_cell_type":"markdown"},"source":"# **Entrega Parcial 2**","block_group":"754c71351b944a2191b4bc1215da71bc"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"a2fbf90275b84abc9efb217f8722a11d","deepnote_cell_type":"markdown"},"source":"## **Objetivos**\n\nEn esta segunda parte, nos enfocaremos en profundizar y expandir nuestras capacidades de ML a través de las siguientes secciones clave:\n- Optimización de modelos\n- Interpretabilidad\n- Re-entrenamiento \n- Tracking\n- Despliegue\n\nNOTA: Los puntos desarrollados en esta entrega deben ser programados de forma funcional para facilitar su futura integración en un pipeline productivo con `Airflow`. No se espera la creación del pipeline en esta étapa, sin embargo, es crucial que el código esté preparado para su incorporación posterior.\n\n**<u>Recordatorio</u>: Para esta entrega sólo deben subir sus predicciones a CodaLab. El informe lo deberán subir en la tercera y última entrega.**\n\n## **Puntos a Desarrollar:**\n\nA continuación se describen las tareas a desarrollar en la presente fase.\n\n### **1. Optimización de modelos**\n\nA partir del análisis realizado en la primera entrega, deben desarrollar código para optimizar el performance de su modelo. Para esto, se espera que implementen técnicas de optimización de hiperparámetros vistas en clase (como `Optuna`) y de esta manera hacer mas eficiente el proceso de optimización. Recuerden optimizar hiperparámetros del modelo y de los pre procesadores utilizados (OneHot, Scalers, etc). Además, se espera que sean capaces de responder preguntas como:\n- ¿Qué métrica decidieron optimizar? ¿Porqué?\n- ¿Cuanto tiempo le destinaron a esta etapa? ¿Existen indicios de que resultados puedan mejorar destinando más tiempo?\n- ¿Qué hiperparámetro tuvo un mayor impacto en el performance de su modelo?\n\n### **2. Interpretabilidad**\n\nEn esta sección ustedes deben ser capaces de explicar el funcionamiento de su modelo a través de las técnicas vistas en clases. A partir de sus resultados, deben ser capaces de responder preguntas como:\n- ¿Podría explicar el funcionamiento de su modelo para una predicción en particular? Si es así, explique 3 ejemplos.\n- ¿Qué atributo tiene una mayor importancia en la salida de su modelo? ¿Tiene esto sentido con el problema de negocio?\n- ¿Existe alguna interacción entre atributos que sea relevante para el modelo?\n- ¿Podría existir sesgo hacia algún atributo en particular? ¿Cuál?\n\n### **3. Re-entrenamiento de  Modelos**\n\nCon la variación y entrega de nuevos datos, un proyecto de data-science debe incluir este paso. Sin embargo, entrenar con todos los datos puede ser costoso. Es importante comprender que un re-entrenamiento puede ser caro y requiere herramientas adecuadas. Como primera aproximación a este paradigma, se les pide lo siguiente:\n\n- Diseñar y ejecutar estrategias de re-entrenamiento para mantener la precisión y relevancia de los modelos, utilizando estrategias de partial fit.\n- Automatizar el proceso de actualización de modelos basados en nuevos datos y feedback recibido a través de una función.\n- Acompañar el re-entrenamiento de una etapa de optimización.\n\nPodría serles útil la inicialización de modelos en base a pesos pasados. Mayor información la pueden encontrar en el siguiente [link](https://stackoverflow.com/questions/38079853/how-can-i-implement-incremental-training-for-xgboost).\n\n### 4. Tracking con MLFlow:\nDurante el modelamiento suceden muchas cosas, por lo que es relevante hacer un tracking de todos los elementos generados por el modelo: métricas de desempeño, modelo, hiperparámetros, importancia de optimización, interpretabilidad, etc.\n\n- Configurar MLFlow para rastrear experimentos, entrenamientos y versiones de modelos.\n- Generar el tracking de los pasos más relevantes del modelo.\n\n### 5. Creación de una aplicación web con Gradio y FastAPI:\nNuestro objetivo es entregar este producto a un cliente final, por lo que debe ser fácilmente consultable a través de una aplicación. Una buena alternativa es la creación de una aplicación web a través de Gradio y FastAPI. En particular, se les pide:\n\n- Desarrollar el frontend en Gradio. El front debe ser amigable y permitir al usuario realizar predicciones de manera sencilla e intuitiva.\n- Desarrollar el backend en FastAPI con la lógica de inferencia del modelo. \n- La aplicación web debe aceptar la carga de datos a través de un archivo plano .csv y la inputación manual de los datos a predecir en un formulario (a la hora de la predicción, ambas vías deben estar habilitadas pero el usuario debe escoger sólo un método).\n- El backend y el frontend deben comunicarse para la generación de predicciones.\n- Tanto el backend como el frontend deben estar dockerizados. Con esto, aseguramos la escalabilidad, portabilidad y despliegue eficiente de la aplicación web en diferentes entornos.\n\nPara la utilización de Docker, les podría ser de utilidad la [cheatsheet](https://dockerlabs.collabnix.com/docker/cheatsheet/) de dockerlabs.\n","block_group":"753af9e4d4aa4d0ca1c5dce2b0bea7c8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"6f29690e27a54c4291aaeee3947845b0","deepnote_cell_type":"markdown"},"source":"# Instrucciones del Informe\n\nLa siguiente lista detalla las secciones extras que debe agregar a su notebook para resolver el proyecto. \nEs importante que al momento de desarrollar cada una de las secciones, estas sean escritas en un formato tipo **informe**, donde describan detalladamente cada uno de los puntos realizados. Recuerden utilizar lo descrito en la sección *Puntos a Desarrollar* para escribir el informe.\n\n## Optimización de Modelo y Despliegue (Entrega Parcial 2)\n\n### **1. Optimización de modelos [0.5 puntos]**\nAcá se explica la forma en la que se realizó la optimización de los modelos. Hiperparámetros ocupados.\nDeberán usar `Optuna` para tunear hiperparámetros. Además de crear pipelines para cada uno de los modelos.\n\nAlgunas ideas para mejorar el rendimiento de sus modelos:\n- Técnicas de selección de atributos.\n- Variar el imputador de datos, en caso de usarlo.\n\n### **2. Interpretabilidad [0.5 puntos]**\n\nUtilización de `SHAP`, `Anchors` u otras herramientas de interpretabilidad, para ver la importancia de cada atributo en el modelo final. Explicar o justificar la importancia de cada uno.\n\n### **3. Tracking con MLFlow [0.6 pts]**\nResultados de los tracking de los modelos. Metricas de desempeño, modelo, hiperparámetros, importancia de optimización, interpretabilidad, etc. Para esta parte, le podría de ser utilidad el quickstart guide de MLFlow [link](https://mlflow.org/docs/latest/tracking.html#quickstart), al igual que la clase .\n\nNota: Recuerden asignar nombres descriptivos a sus experimentos para así reconocer de manera fácil cada uno.\n\n### **4. Desarrollo de Aplicación Web [0.6 pts]**\n\nDado que la finalidad del proyecto es entregar una aplicación al cliente, esta tiene que ser consultable.\nPara la realización de esta parte, sobre todo la parte de Docker, ver la clase sobre contenedores.\n\n## **Recordatorio**\n\nLa tercera y última entrega debe concatenar el trabajo de las dos entregas parciales previas. Por esto, es sumamente relevante que en el entregable entreguen todos los trabajos previos parciales en este documento final, donde se documente cada uno de los pasos que se han señalados previamente.\n\n<p align=\"center\">\n  <img src=\"https://th.bing.com/th?id=OIF.nuHXDGSH1%2bnZj8FZlw2MIg&rs=1&pid=ImgDetMain\" width=\"350\">\n</p>","block_group":"95e4afaa2bd24597a3ee2d0f4ddc99f7"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"b717eb9e1c3b4b7ca0648289d90be804","deepnote_cell_type":"markdown"},"source":"","block_group":"630682f616c0464294c26c05ffbdeb30"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_app_layout":"powerful-article","deepnote_app_reactivity_enabled":true,"deepnote_notebook_id":"2939a76dd7c14f7f948714e40aa8bd20"}}