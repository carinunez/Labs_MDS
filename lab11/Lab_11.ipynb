{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "# **Laboratorio 11: LLM y Agentes Aut칩nomos 游뱄**\n",
        "\n",
        "MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pbWVyntzbvL"
      },
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti치n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6ikgVYzghB"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados**\n",
        "\n",
        "- Nombre de alumno 1: Carolina Nu침ez\n",
        "- Nombre de alumno 2: Alonso Uribe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ-owchzjFf"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Repositorio游눹](https://github.com/carinunez/Labs_MDS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuwsXrKzmkK"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resoluci칩n de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas 칰tiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci칩n van a usar m칠todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOcejYb6uzOO"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsecci칩n es que puedan implementar m칠todos de RL y as칤 generar una estrategia para jugar el cl치sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c칩digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **1.1.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "`escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 5000 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica? 쮺칩mo podr칤a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p2PrLLR9yju"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9JsFA1wGmnH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **1.1.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-d7d8GFf7F6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una funci칩n que reciba un estado y retorne la accion del agente. Luego, use esta funci칩n para entregar la acci칩n escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "쯉on coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: 쮸 que clase de python pertenecen los estados? Pruebe a usar el m칠todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh8XlGyzwtRp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n 2.1, en esta secci칩n usted se encargar치 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvQUyuZ_FtZ4"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el par치metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU4lGX3wpN6"
      },
      "source": [
        "Noten que se especifica el par치metro `continuous = True`. 쯈ue implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Adem치s, se le facilita la funci칩n `export_gif` para el ejercicio 2.2.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRiWpSo9yfr9"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci칩n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **1.2.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. 쮺omo se distinguen las acciones de este ambiente en comparaci칩n a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especific칩 el par치metro `continuous = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      },
      "source": [
        "`escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 10 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bwc3A0GX7a8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_6Ia9uoF7Hs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **1.2.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ophyU3KrWrwl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **1.2.5 Optimizaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par치metros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la funci칩n `export_gif` para estudiar el comportamiento de su agente en la resoluci칩n del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor a칰n si adem치s adjuntan el gif en el markdown)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aItYF6sr6F_6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      },
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta secci칩n se enfocar치n en habilitar un Chatbot que nos permita responder preguntas 칰tiles a trav칠s de LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4fPRRihGLe"
      },
      "source": [
        "### **2.0 Configuraci칩n Inicial**\n",
        "<!--\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p> -->\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud2Xm_k-hFJn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      },
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<!-- <p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p> -->\n",
        "\n",
        "El objetivo de esta subsecci칩n es que habiliten un chatbot que pueda responder preguntas usando informaci칩n contenida en documentos PDF a trav칠s de **Retrieval Augmented Generation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      },
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como m칤nimo.\n",
        "  - 50 p치ginas de contenido como m칤nimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas acad칠micos, laborales o de ocio. Aprovechen este ejercicio para construir algo 칰til y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "pH-I97c5wPUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D1tIRCi4oJJ"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai"
      ],
      "metadata": {
        "id": "caUD7ufNwfhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet faiss-cpu langchain_community pypdf"
      ],
      "metadata": {
        "id": "Io4tl9IgyVAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = ['/content/gdrive/MyDrive/pdf_LLM/506.pdf',\n",
        "            #  '/content/gdrive/MyDrive/pdf_LLM/Encyclopedia of Foods. A Guide to Healthy Nutrition ( PDFDrive.com ).pdf',\n",
        "             '/content/gdrive/MyDrive/pdf_LLM/La-guia-peq-cambios-castella.pdf',\n",
        "             '/content/gdrive/MyDrive/pdf_LLM/Manual_basico_N_clinica_y_Dietetica_Valencia_2012.pdf',\n",
        "             '/content/gdrive/MyDrive/pdf_LLM/cb2395en.pdf',\n",
        "             '/content/gdrive/MyDrive/pdf_LLM/food-for-thought-mental-health-nutrition-briefing-march-2017.pdf',\n",
        "             '/content/gdrive/MyDrive/pdf_LLM/nutrients-14-00750.pdf'] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un m칤nimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"P치ginas insuficientes: {total_paginas}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r811-P71nizA"
      },
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-yXAdCSn4JM"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "docs = PyPDFLoader(doc_paths[-1]).load()\n",
        "\n",
        "for doc in doc_paths[:-1]:\n",
        "  new_doc = PyPDFLoader(doc).load()\n",
        "  docs.extend(new_doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits docs in chunks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs) # dividir documentos en chunks"
      ],
      "metadata": {
        "id": "XV1spUnLzL8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "vectorstore"
      ],
      "metadata": {
        "id": "kE8h7lFIzGmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
        "                                     )"
      ],
      "metadata": {
        "id": "mMRpyP0e0Aiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"que frutas recomiendas para una persona deshidratada\" # pregunta\n",
        "# relevant_documents = retriever.invoke(question) # top k documentos relevantes a la pregunta\n",
        "# relevant_documents"
      ],
      "metadata": {
        "id": "Fz4TpvNE0DI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "15F4ydsr1c8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUkP5zrnyBK"
      },
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la soluci칩n RAG a trav칠s de una *chain* y gu치rdela en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPIySdDFn99l",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain\n",
        "print(retriever_chain.invoke(\"lista de verduras con mayor contenido en fibra\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
        "    temperature=0.2, # probabilidad de \"respuestas creativas\"\n",
        "    max_tokens=None, # sin tope de tokens\n",
        "    timeout=None, # sin timeout\n",
        "    max_retries=2, # n칰mero m치ximo de intentos\n",
        ")\n",
        "\n",
        "# Entrego contexto para las respuestas\n",
        "rag_template = '''\n",
        "Eres un asistente experto en nutrici칩n y salud. Haces recomendaciones sobre alimentos\n",
        "a consumir seg칰n el contexto que se te entrega.\n",
        "Tu 칰nico rol es contestar preguntas del usuario a partir de informaci칩n relevante que te sea proporcionada.\n",
        "Responde siempre de la forma m치s completa posible y usando toda la informaci칩n entregada.\n",
        "Responde s칩lo lo que te pregunten a partir de la informaci칩n relevante, NUNCA inventes una respuesta.\n",
        "Responde en espa침ol, a menos que se te indique lo contrario.\n",
        "\n",
        "Informaci칩n relevante: {context}\n",
        "Pregunta: {question}\n",
        "Respuesta 칰til:\n",
        "'''\n",
        "\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "# Finalmente, condensamos todo en una chain para recuperar informaci칩n relevante y responder al mismo tiempo:\n",
        "\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "question = \"que frutas recomiendas para la deshidrataci칩n?\"\n",
        "response = rag_chain.invoke(question)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "W7Ar_lIFWuM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"entregame 5 verduras con alto contenido en fibra y su cantidad, si dispones de ella'\"\n",
        "# response = rag_chain.invoke(question)\n",
        "# print(response)"
      ],
      "metadata": {
        "id": "Yhcm2MgSeABQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"que alimentos recomeindas para reducir la obesidad\"\n",
        "response = rag_chain.invoke(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "TRtc383vcfAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rag_chain.invoke('recomendaciones de meriendas dulces'))"
      ],
      "metadata": {
        "id": "aErx77-GMaBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg5S5i_n-kL"
      },
      "source": [
        "#### **2.1.4 Verificaci칩n de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci칩n para cada una. 쯉u soluci칩n RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: 쯈ui칠n es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_UiEn1hoZYR"
      },
      "outputs": [],
      "source": [
        "referencia = [\n",
        "    ('que alimentos debe tener la dieta de una persona con diabetes?',\n",
        "     #respuesta\n",
        "    'Frutas.Verduras.Granos integrales.Legumbres, como frijoles y guisantes. Productos l치cteos bajos en grasa, como leche y queso.'),\n",
        "    ('alimentos recomendados para la deshidrataci칩n',\n",
        "     \"Beba l칤quidos. A veces, los l칤quidos muy fr칤os resultan m치s f치ciles de beber.\\\n",
        "     Recuerde que los alimentos contienen l칤quidos. Procure comer frutas, verduras,\\\n",
        "     sopas, gelatinas, paletas de helado y otros alimentos hidratados\"),\n",
        "    ('que alimentos recomeindas para reducir la obesidad',\n",
        "     'nn')]\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop"
      ],
      "metadata": {
        "id": "Zse_i-2DeG-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8d5zTMHoUgF"
      },
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperpar치metros (0.5 puntos)**\n",
        "\n",
        "Extienda el an치lisis del punto 2.1.4 analizando c칩mo cambian las respuestas entregadas cambiando los siguientes hiperpar치metros:\n",
        "- `Tama침o del chunk`. (*쮺칩mo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*쯈u칠 pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de b칰squeda`. (*쮺칩mo afecta el tipo de b칰squeda a las respuestas de mi RAG?*)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "vectorstore\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain"
      ],
      "metadata": {
        "id": "CI2r2huOaO6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))\n",
        "  print('---------------------------------------')"
      ],
      "metadata": {
        "id": "xhBGcL2eYM--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDh_QgeXLGHc"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "vectorstore\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "vectorstore\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 3}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "# Finalmente, condensamos todo en una chain para recuperar informaci칩n relevante y responder al mismo tiempo:\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))\n",
        "  print('---------------------------------------')"
      ],
      "metadata": {
        "id": "2rYyrNwmaSuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al aumentar el tama침o del chunk, se tiene m치s contexto por lo que tiene sentido que las respuestas entregadas la segunda prueba tengan mayor extension."
      ],
      "metadata": {
        "id": "3eGk92MLZqCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambio de numero de chunks a recuperar\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "vectorstore\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 6}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "# Finalmente, condensamos todo en una chain para recuperar informaci칩n relevante y responder al mismo tiempo:\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))\n",
        "  print('---------------------------------------')"
      ],
      "metadata": {
        "id": "C9FWmZW9cdEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambio de numero de chunks a recuperar\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # m칠todo de b칰squeda\n",
        "                                     search_kwargs={\"k\": 2}, # n춿 documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "# Finalmente, condensamos todo en una chain para recuperar informaci칩n relevante y responder al mismo tiempo:\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))\n",
        "  print('---------------------------------------')"
      ],
      "metadata": {
        "id": "17KMKaLAeaOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1.5.1 cambio en num archivos por recuperar"
      ],
      "metadata": {
        "id": "QkcMgsz-ec7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambio de numero de chunks a recuperar\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "\n",
        "# Maximum Marginal Relevance Search\n",
        "retriever = vectorstore.as_retriever(search_type='mmr', search_kwargs={\"k\": 2})\n",
        "\n",
        "retriever_chain = retriever | format_docs # chain\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "\n",
        "# Finalmente, condensamos todo en una chain para recuperar informaci칩n relevante y responder al mismo tiempo:\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "        \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        ")\n",
        "\n",
        "for i, ref in enumerate(referencia):\n",
        "  print('Pregunta: ', ref[0])\n",
        "  print('Respuesta de ref: ', ref[1])\n",
        "  print('Respuesta RAG chain: ', rag_chain.invoke(ref[0]))\n",
        "  print('---------------------------------------')"
      ],
      "metadata": {
        "id": "6uCd7IOwegz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJiPPM0giX8"
      },
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n anterior, en esta secci칩n se busca habilitar **Agentes** para obtener informaci칩n a trav칠s de tools y as칤 responder la pregunta del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47l7Mjfrk0N"
      },
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de b칰squeda **Tavily**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "# inicializamos tool\n",
        "search_tavily = TavilySearchResults(max_results = 2, include_raw_content=True)\n",
        "tools = [search_tavily]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_tavily.invoke('qu칠 frutas tienen alto contenido de fibra?')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q7nG2E1uUrPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SonB1A-9rtRq"
      },
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wikipedia"
      ],
      "metadata": {
        "id": "DTVliBeU28WX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehJJpoqsr26-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=2,\n",
        "                                  doc_content_chars_max=600,\n",
        "                                  lang='es')\n",
        "search_wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "\n",
        "tools += [search_wiki]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_wiki.invoke('qu칠 frutas tienen alto contenido de fibra?')"
      ],
      "metadata": {
        "id": "sVbKFiDB5QJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUIMdX6r0ne"
      },
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg칰rese que su agente responda en espa침ol. Por 칰ltimo, guarde el agente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD1_n0wrsDI5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# Carga del prompt para usar ReAct\n",
        "react_prompt = hub.pull(\"hwchase17/react\") + PromptTemplate.from_template(\n",
        "                                                \"\"\"\n",
        "                                                Responde utilizando todas las tools disponibles.\n",
        "                                                Responde en espa침ol.\n",
        "                                                \"\"\")\n",
        "\n",
        "\n",
        "agente = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "agente_executor = AgentExecutor(agent=agente, tools=tools,\n",
        "                                verbose=True,\n",
        "                                # return_intermediate_steps=True,\n",
        "                                max_iterations=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV0JxK3r-XG"
      },
      "source": [
        "#### **2.2.4 Verificaci칩n de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y aseg칰rese que el agente est칠 ocupando correctamente las tools disponibles. 쮼n qu칠 casos el agente deber칤a ocupar la tool de Tavily? 쮼n qu칠 casos deber칤a ocupar la tool de Wikipedia?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se necesite una definici칩n o informaci칩n objetiva sobre un tema, lo ideal es utilizar la tool de Wikipedia. En caso de que se est칠 buscando una respuesta, lo ideal es usar la tool de Tavily que busca, filtra y extrae informaci칩n de distintas fuentes en l칤nea."
      ],
      "metadata": {
        "id": "6mfZKeTGglyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agente_executor.invoke({'input':'qu칠 pas칩 con Cathy Barriga?'})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LoFOn8TIWMev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agente_executor.invoke({'input':'qui칠n es el nuevo alcalce de Maip칰?'})"
      ],
      "metadata": {
        "id": "tcdS8huy0U_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agente_executor.invoke({'input':'칰ltimos albums de los miembros de BTS'})"
      ],
      "metadata": {
        "id": "zY__1iO61w82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbDTYiogquv"
      },
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci칩n es encapsular las funcionalidades creadas en una soluci칩n multiagente con un **supervisor**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-iUfH0WvI6m"
      },
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la soluci칩n RAG de la secci칩n 2.1 y el agente de la secci칩n 2.2 a *tools* (una tool por cada uno)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw1cfTtvv1AZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQYNjT_0vPCg"
      },
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2ZY0BAv1RD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3zWlvyvY7K"
      },
      "source": [
        "#### **2.3.3 Verificaci칩n de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. 쮺칩mo var칤an las respuestas bajo este enfoque?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_1t0zkgv1qW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      },
      "source": [
        "#### **2.3.4 An치lisis (0.25 puntos)**\n",
        "\n",
        "쯈u칠 diferencias tiene este enfoque con la soluci칩n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUlJxqoLK5r"
      },
      "source": [
        "`escriba su respuesta ac치`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      },
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebasti치n\"\n",
        "  - Respuesta esperada: \"Hola Sebasti치n! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebasti치n\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci칩n entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es v치lido <u>s칩lo para la secci칩n 2 de Large Language Models.</u>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFc3jBT5g0kT"
      },
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav칠s de `gradio`, una librer칤a especializada en el levantamiento r치pido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librer칤a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8TsvnCPbkIA"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBztEUovKsF"
      },
      "source": [
        "Luego s칩lo deben ejecutar el siguiente c칩digo e interactuar con la interfaz a trav칠s del notebook o del link generado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3KedQSvg1-n"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Funci칩n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = ... # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy 칰til :)\", # tambi칠n la descripci칩n\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}